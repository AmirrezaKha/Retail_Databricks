{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ba4f9ed-0cf4-4f6e-8437-4d582d959800",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# Fabric Notebook 3: Association Rules (Fixed for Power BI)\n",
    "# ======================================\n",
    "\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "import pyspark.sql.functions as F\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from mlflow import MlflowClient\n",
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "# Setup MLflow\n",
    "mlflow.set_experiment(\"Retail_ML_Experiments\")\n",
    "client = MlflowClient()\n",
    "registry_name = \"retail_ML_basket\"\n",
    "try:\n",
    "    client.create_registered_model(registry_name)\n",
    "except:\n",
    "    print(f\"â„¹ï¸ Registry {registry_name} already exists\")\n",
    "\n",
    "# Load and prepare data\n",
    "df = spark.table(\"Fact_Sales_Products\") \\\n",
    "    .groupBy(\"Transaction_ID\") \\\n",
    "    .agg(F.collect_set(\"Product_ID\").alias(\"items\"))\n",
    "\n",
    "# Train FP-Growth\n",
    "with mlflow.start_run(run_name=\"FPGrowth\") as run:\n",
    "    df_filtered = df.filter(F.size(\"items\") >= 2)\n",
    "    fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.005, minConfidence=0.05)\n",
    "    model = fpGrowth.fit(df_filtered)\n",
    "\n",
    "    mlflow.log_param(\"minSupport\", 0.02)\n",
    "    mlflow.log_param(\"minConfidence\", 0.3)\n",
    "    mlflow.spark.log_model(model, \"model\")\n",
    "\n",
    "    try:\n",
    "        mv = client.create_model_version(name=registry_name,\n",
    "                                         source=f\"runs:/{run.info.run_id}/model\",\n",
    "                                         run_id=run.info.run_id)\n",
    "        print(f\"Model registered as version {mv.version}\")\n",
    "    except:\n",
    "        print(\"Registry skipped\")\n",
    "\n",
    "    # ==========================\n",
    "    # Convert arrays to strings\n",
    "    # ==========================\n",
    "    rules_df = model.associationRules \\\n",
    "        .withColumn(\"antecedent_str\", concat_ws(\",\", \"antecedent\")) \\\n",
    "        .withColumn(\"consequent_str\", concat_ws(\",\", \"consequent\")) \\\n",
    "        .drop(\"antecedent\", \"consequent\")\n",
    "\n",
    "    items_df = model.freqItemsets \\\n",
    "        .withColumn(\"items_str\", concat_ws(\",\", \"items\")) \\\n",
    "        .drop(\"items\")\n",
    "\n",
    "    # Save results for Power BI\n",
    "    rules_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(\"PowerBI_Basket_Analysis\")\n",
    "    print(\"âœ… Saved association rules to PowerBI_Basket_Analysis\")\n",
    "\n",
    "    items_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(\"PowerBI_Frequent_Itemsets\")\n",
    "    print(\"âœ… Saved frequent itemsets to PowerBI_Frequent_Itemsets\")\n",
    "        \n",
    "    # Show frequent itemsets\n",
    "    print(\"ðŸ“Š Frequent Itemsets:\")\n",
    "    items_df.show(10, truncate=False)\n",
    "\n",
    "    # Show association rules\n",
    "    print(\"ðŸ“ˆ Association Rules:\")\n",
    "    rules_df.show(10, truncate=False)\n",
    "\n",
    "    # Show predictions (transactions + recommended items as string)\n",
    "    predictions = model.transform(df_filtered) \\\n",
    "        .withColumn(\"predicted_items\", concat_ws(\",\", \"prediction\"))\n",
    "    print(\"ðŸ›’ Predictions with recommendations:\")\n",
    "    predictions.show(10, truncate=False)\n",
    "\n",
    "    # Count of rules and itemsets\n",
    "    print(f\"âœ… Total frequent itemsets: {items_df.count()}\")\n",
    "    print(f\"âœ… Total association rules: {rules_df.count()}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Retail_ml_Associate",
   "widgets": {}
  },
  "dependencies": {},
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
